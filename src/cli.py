#!/usr/bin/env python3
"""
CLI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è production deployment —Å–∏—Å—Ç–µ–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ML –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
"""

import argparse
import sys
import os
import json
import numpy as np
from pathlib import Path
from datetime import datetime
import pandas as pd

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from ga_optimizer import GAConfig, run_genetic_algorithm
from pipeline_processor import decode_chromosome_full, process_data, train_model
from deployment.production_pipeline import ProductionPipeline
from deployment.model_serializer import UniversalModelSerializer
from modeling.model_trainer import ModelTrainer


class MLPipelineCLI:
    """–ö–æ–º–∞–Ω–¥–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è ML –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    
    def __init__(self):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–ø–∞–ø–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è src)
        current_dir = Path(__file__).parent  # src/
        project_root = current_dir.parent  # project/
        self.models_dir = project_root / "models"
        self.results_dir = project_root / "results" 
        self.models_dir.mkdir(exist_ok=True)
        self.results_dir.mkdir(exist_ok=True)
        
    def run_chromosome(self, args):
        """–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ö—Ä–æ–º–æ—Å–æ–º—ã, –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        print(f"üß¨ –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ö—Ä–æ–º–æ—Å–æ–º—ã: {args.chromosome}")
        print(f"üìä –î–∞—Ç–∞—Å–µ—Ç: {args.dataset}")
        print(f"üéØ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {args.target}")
        
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ö—Ä–æ–º–æ—Å–æ–º—É
            chromosome = [int(x.strip()) for x in args.chromosome.split(',')]
            print(f"üîç –•—Ä–æ–º–æ—Å–æ–º–∞: {chromosome}")
            
            decoded_info = decode_chromosome_full(chromosome, verbose=True)
            params = decoded_info['pipeline_params']
            
            print(f"\n‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–π–ø–ª–∞–π–Ω–∞:")
            for key, value in params.items():
                print(f"  {key}: {value}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            train_data, test_data, research_path = process_data(
                args.dataset, None, args.target,
                imputation_method=params['imputation_method'],
                imputation_params=params['imputation_params'],
                outlier_method=params['outlier_method'],
                outlier_params=params['outlier_params'],
                encoding_method=params['encoding_method'],
                encoding_params=params['encoding_params'],
                resampling_method=params['resampling_method'],
                resampling_params=params['resampling_params'],
                scaling_method=params['scaling_method'],
                scaling_params=params['scaling_params'],
                save_processed_data=False,
                save_model_artifacts=False
            )
            
            print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {train_data.shape}")
            print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {test_data.shape}")
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é ModelTrainer
            print(f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {params['model_type']}")
            trainer = ModelTrainer(
                model_type=params['model_type'],
                model_hyperparameters=params['model_params']
            )
            
            metrics, feature_importance = trainer.train(
                train_data, test_data, args.target,
                output_path=None,
                plot_learning_curves=False,
                save_run_results=False
            )
            
            if not metrics:
                print("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
                return False
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  
            model_name = f"{Path(args.dataset).stem}_{params['model_type']}_{timestamp}"
            model_save_path = self.models_dir / model_name
            
            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é UniversalModelSerializer
            model_info = UniversalModelSerializer.save_model(
                trainer.model, 
                str(model_save_path),
                model_type=params['model_type']
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            metadata = {
                'model_name': model_name,
                'dataset': args.dataset,
                'target_column': args.target,
                'features': list(train_data.columns[train_data.columns != args.target]),
                'chromosome': chromosome,
                'pipeline_config': params,
                'metrics': metrics,
                'model_info': model_info,
                'created_at': timestamp,
                'source': 'cli_chromosome'
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ 
            metadata_path = self.models_dir / f"{model_name}_metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
            
            auprc = metrics.get('auprc', metrics.get('accuracy', 0))
            print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
            print(f"üìÅ –ü–∞–ø–∫–∞ –º–æ–¥–µ–ª–∏: {model_save_path}")
            print(f"üìÑ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata_path}")
            print(f"üìà –ú–µ—Ç—Ä–∏–∫–∞: {auprc:.4f}")
            print(f"üß¨ –•—Ä–æ–º–æ—Å–æ–º–∞: {chromosome}")
            
            return True
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_ga(self, args):
        """–ó–∞–ø—É—Å–∫ –ì–ê —Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        print(f"üß¨ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞")
        print(f"üìä –î–∞—Ç–∞—Å–µ—Ç: {args.train}")
        print(f"üéØ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {args.target}")
        print(f"üë• –ü–æ–ø—É–ª—è—Ü–∏—è: {args.population}")
        print(f"üîÑ –ü–æ–∫–æ–ª–µ–Ω–∏—è: {args.generations}")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ì–ê
            ga_config = GAConfig(
                train_path=args.train,
                test_path=None,
                target_column=args.target,
                population_size=args.population,
                num_generations=args.generations,
                elitism_percent=args.elitism,
                mutation_rate=args.mutation,
                tournament_size=args.tournament,
                generate_learning_curves=args.learning_curves
            )
            
            print(f"\n‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {ga_config}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ì–ê
            print("\nüöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
            results = run_genetic_algorithm(ga_config)
            
            if not results or results['best_chromosome'] is None:
                print("‚ùå –ì–ê –Ω–µ –Ω–∞—à–µ–ª –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ")
                return False
            
            best_chromosome = results['best_chromosome']
            best_fitness = results['best_fitness']
            
            print(f"\nüèÜ –ù–∞–π–¥–µ–Ω–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ!")
            print(f"üìà –õ—É—á—à–∏–π —Ñ–∏—Ç–Ω–µ—Å: {best_fitness:.4f}")
            print(f"üß¨ –õ—É—á—à–∞—è —Ö—Ä–æ–º–æ—Å–æ–º–∞: {best_chromosome}")
            
            # –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if args.auto_save:
                print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
                
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ª—É—á—à—É—é —Ö—Ä–æ–º–æ—Å–æ–º—É
                decoded_info = decode_chromosome_full(best_chromosome, verbose=False)
                params = decoded_info['pipeline_params']
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                train_data, test_data, research_path = process_data(
                    args.train, None, args.target,
                    imputation_method=params['imputation_method'],
                    imputation_params=params['imputation_params'],
                    outlier_method=params['outlier_method'],
                    outlier_params=params['outlier_params'],
                    encoding_method=params['encoding_method'],
                    encoding_params=params['encoding_params'],
                    resampling_method=params['resampling_method'],
                    resampling_params=params['resampling_params'],
                    scaling_method=params['scaling_method'],
                    scaling_params=params['scaling_params'],
                    save_processed_data=False,
                    save_model_artifacts=False
                )
                
                # –û–±—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é ModelTrainer
                print(f"üöÄ –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {params['model_type']}")
                trainer = ModelTrainer(
                    model_type=params['model_type'],
                    model_hyperparameters=params['model_params']
                )
                
                metrics, feature_importance = trainer.train(
                    train_data, test_data, args.target,
                    output_path=None,
                    plot_learning_curves=False,
                    save_run_results=False
                )
                
                # –°–æ–∑–¥–∞–µ–º –∏–º—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_name = f"{Path(args.train).stem}_GA_best_{timestamp}"
                model_save_path = self.models_dir / model_name
                
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é UniversalModelSerializer
                model_info = UniversalModelSerializer.save_model(
                    trainer.model, 
                    str(model_save_path),
                    model_type=params['model_type']
                )
                
                # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                metadata = {
                    'model_name': model_name,
                    'dataset': args.train,
                    'target_column': args.target,
                    'features': list(train_data.columns[train_data.columns != args.target]),
                    'chromosome': best_chromosome,
                    'pipeline_config': params,
                    'metrics': metrics,
                    'model_info': model_info,
                    'ga_results': {
                        'best_fitness': best_fitness,
                        'fitness_history': results['fitness_history']
                    },
                    'created_at': timestamp,
                    'source': 'genetic_algorithm'
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata_path = self.models_dir / f"{model_name}_metadata.json"
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
                
                print(f"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
                print(f"üìÅ –ü–∞–ø–∫–∞ –º–æ–¥–µ–ª–∏: {model_save_path}")
                print(f"üìÑ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata_path}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict(self, args):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º"""
        print(f"üîÆ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {args.model}")
        print(f"üìä –î–∞–Ω–Ω—ã–µ: {args.data}")
        
        try:
            # –ò—â–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            metadata_path = None
            if args.model.endswith('_metadata.json'):
                metadata_path = Path(args.model)
            else:
                # –ò—â–µ–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ models
                metadata_path = self.models_dir / f"{args.model}_metadata.json"
                if not metadata_path.exists():
                    metadata_path = self.models_dir / f"{args.model.replace('.pkl', '')}_metadata.json"
            
            if not metadata_path.exists():
                print(f"‚ùå –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {args.model}")
                print(f"üí° –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–º–∞–Ω–¥–æ–π: list-models")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {metadata_path}")
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            print(f"üìã –ú–æ–¥–µ–ª—å: {metadata.get('model_name', 'unknown')}")
            print(f"üéØ –¶–µ–ª—å: {metadata.get('target_column', 'unknown')}")
            print(f"ü§ñ –¢–∏–ø: {metadata.get('pipeline_config', {}).get('model_type', 'unknown')}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {args.data}")
            data = pd.read_csv(args.data)
            
            print(f"üìã –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {data.shape}")
            print(f"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(data.columns)}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")
            target_column = metadata.get('target_column')
            expected_features = metadata.get('features', [])
            
            print(f"üìä –û–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(expected_features)}): {expected_features[:5]}{'...' if len(expected_features) > 5 else ''}")
            print(f"üìä –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ({len(data.columns)}): {list(data.columns)[:5]}{'...' if len(data.columns) > 5 else ''}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            missing_features = set(expected_features) - set(data.columns)
            if missing_features:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {list(missing_features)[:5]}{'...' if len(missing_features) > 5 else ''}")
            
            extra_features = set(data.columns) - set(expected_features) - {target_column}
            if extra_features:
                print(f"‚ÑπÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(extra_features)[:5]}{'...' if len(extra_features) > 5 else ''}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –º–æ–¥–µ–ª—å
            print(f"\nüîÆ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
            model_info = metadata.get('model_info')
            if not model_info:
                print("‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
                return False
            
            # –ò—â–µ–º –ø–∞–ø–∫—É —Å –º–æ–¥–µ–ª—å—é
            model_name = metadata.get('model_name')
            model_folder = self.models_dir / model_name
            
            if not model_folder.exists():
                print(f"‚ùå –ü–∞–ø–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_folder}")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            try:
                model, loaded_model_info = UniversalModelSerializer.load_model(str(model_folder))
                print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                print(f"üîß –¢–∏–ø: {loaded_model_info.get('model_type', 'unknown')}")
                print(f"üì¶ –§–æ—Ä–º–∞—Ç: {loaded_model_info.get('serialization_format', 'unknown')}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                return False
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            target_column = metadata.get('target_column')
            expected_features = metadata.get('features', [])
            
            # –£–¥–∞–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –∫–æ–ª–æ–Ω–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            prediction_data = data.copy()
            if target_column in prediction_data.columns:
                prediction_data = prediction_data.drop(columns=[target_column])
                print(f"‚ÑπÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ '{target_column}' –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            missing_features = set(expected_features) - set(prediction_data.columns)
            if missing_features:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {list(missing_features)}")
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                for feature in missing_features:
                    prediction_data[feature] = 0
                    print(f"  + –î–æ–±–∞–≤–ª–µ–Ω '{feature}' = 0")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            prediction_data = prediction_data[expected_features]
            
            print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {prediction_data.shape}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            try:
                predictions = model.predict(prediction_data)
                probabilities = model.predict_proba(prediction_data) if hasattr(model, 'predict_proba') else None
                
                # –î–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                model_type = loaded_model_info.get('model_type', 'unknown')
                if model_type == 'neural_network':
                    # –î–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π predictions –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
                    if predictions.ndim > 1 and predictions.shape[1] > 1:
                        probabilities = predictions
                        predictions = np.argmax(predictions, axis=1)
                    elif predictions.ndim == 1 or predictions.shape[1] == 1:
                        # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                        probabilities = np.column_stack([1 - predictions.ravel(), predictions.ravel()])
                        predictions = (predictions > 0.5).astype(int).ravel()
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
                if probabilities is not None:
                    n_classes = probabilities.shape[1]
                else:
                    n_classes = len(np.unique(predictions))
                
                print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {n_classes}")
                print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {e}")
                return False
            
            print(f"üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
            print(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(predictions)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            n_show = min(10, len(predictions))
            for i in range(n_show):
                prob_str = ", ".join([f"{probabilities[i][j]:.3f}" for j in range(n_classes)])
                print(f"  [{i+1:2d}] –ö–ª–∞—Å—Å: {predictions[i]} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: [{prob_str}])")
            
            if len(predictions) > n_show:
                print(f"  ... –∏ –µ—â–µ {len(predictions) - n_show} –∑–∞–ø–∏—Å–µ–π")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (–≤—Å–µ–≥–¥–∞)
            output_data = data.copy()
            output_data['prediction'] = predictions
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
            for class_idx in range(n_classes):
                output_data[f'probability_class_{class_idx}'] = probabilities[:, class_idx]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if args.output:
                output_file = args.output
            else:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ –ø–∞–ø–∫–µ results –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞  
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–ø–∞–ø–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è src)
                current_dir = Path(__file__).parent  # src/
                project_root = current_dir.parent  # project/
                results_dir = project_root / "results"
                
                # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
                results_dir.mkdir(exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_name = metadata.get('model_name', 'unknown')
                data_path = Path(args.data)
                data_filename = data_path.stem  # –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                
                output_file = results_dir / f"predictions_{data_filename}_{model_name}_{timestamp}.csv"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_data.to_csv(output_file, index=False)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
            full_path = os.path.abspath(str(output_file))
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
            print(f"üìÑ –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {full_path}")
            print(f"üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {len(data)} –∑–∞–ø–∏—Å–µ–π + prediction + {n_classes} probability columns")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def list_models(self, args):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        
        try:
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–º–µ—Å—Ç–æ .pkl —Ñ–∞–π–ª–æ–≤
            metadata_files = list(self.models_dir.glob("*_metadata.json"))
            
            if not metadata_files:
                print("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return False
            
            for metadata_path in sorted(metadata_files):
                model_name = metadata_path.stem.replace('_metadata', '')
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                dataset = Path(metadata.get('dataset', 'unknown')).stem
                target = metadata.get('target_column', 'unknown')
                metrics = metadata.get('metrics', {})
                auprc = metrics.get('auprc', metrics.get('accuracy', 'N/A'))
                created = metadata.get('created_at', 'unknown')
                source = metadata.get('source', 'manual')
                
                print(f"\nü§ñ {model_name}")
                print(f"   üìä –î–∞—Ç–∞—Å–µ—Ç: {dataset}")
                print(f"   üéØ –¶–µ–ª—å: {target}")
                print(f"   üìà –ú–µ—Ç—Ä–∏–∫–∞: {auprc}")
                print(f"   üìÖ –°–æ–∑–¥–∞–Ω: {created}")
                print(f"   üîß –ò—Å—Ç–æ—á–Ω–∏–∫: {source}")
                
                if args.verbose and 'chromosome' in metadata:
                    print(f"   üß¨ –•—Ä–æ–º–æ—Å–æ–º–∞: {metadata['chromosome']}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ pkl —Ñ–∞–π–ª–∞
                pkl_path = self.models_dir / f"{model_name}.pkl"
                if pkl_path.exists():
                    size = pkl_path.stat().st_size / 1024  # KB
                    print(f"   üíæ –ú–æ–¥–µ–ª—å: {size:.1f} KB")
                else:
                    print(f"   üíæ –ú–æ–¥–µ–ª—å: –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ")
            
            print(f"\nüìä –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {len(metadata_files)}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description="CLI –¥–ª—è production deployment —Å–∏—Å—Ç–µ–º—ã ML –ø–∞–π–ø–ª–∞–π–Ω–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  
  # –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ö—Ä–æ–º–æ—Å–æ–º—ã
  python cli.py run-chromosome --chromosome "1,2,0,1,1,2,0,1,0,0,1,1,1,0,0,1,2,3,1,0" \\
                              --dataset "../datasets/diabetes.csv" \\
                              --target "Outcome"
  
  # –ó–∞–ø—É—Å–∫ –ì–ê —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
  python cli.py run-ga --dataset "../datasets/diabetes.csv" \\
                       --target "Outcome" \\
                       --population 10 \\
                       --generations 5 \\
                       --save-best
  
  # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
  python cli.py predict --model "diabetes_logistic_regression_20250608_120000" \\
                        --data "new_data.csv" \\
                        --output "predictions.csv"
  
  # –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
  python cli.py list-models --verbose
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã')
    
    # –ö–æ–º–∞–Ω–¥–∞ run-chromosome
    cmd_chromosome = subparsers.add_parser(
        'run-chromosome', 
        help='–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ö—Ä–æ–º–æ—Å–æ–º—ã —Å —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π'
    )
    cmd_chromosome.add_argument('--chromosome', required=True, 
                              help='–•—Ä–æ–º–æ—Å–æ–º–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "1,2,0,1,..." (20 –≥–µ–Ω–æ–≤)')
    cmd_chromosome.add_argument('--dataset', required=True,
                              help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É')
    cmd_chromosome.add_argument('--target', required=True,
                              help='–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π')
    cmd_chromosome.add_argument('--learning-curves', action='store_true',
                              help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è')
    
    # –ö–æ–º–∞–Ω–¥–∞ run-ga
    cmd_ga = subparsers.add_parser(
        'run-ga',
        help='–ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞'
    )
    cmd_ga.add_argument('--train', '--dataset', required=True,
                       help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
    cmd_ga.add_argument('--target', required=True,
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π')
    cmd_ga.add_argument('--population', type=int, default=10,
                       help='–†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10)')
    cmd_ga.add_argument('--generations', type=int, default=8,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 8)')
    cmd_ga.add_argument('--elitism', type=float, default=0.25,
                       help='–ü—Ä–æ—Ü–µ–Ω—Ç —ç–ª–∏—Ç–∏–∑–º–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.25)')
    cmd_ga.add_argument('--mutation', type=float, default=0.1,
                       help='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.1)')
    cmd_ga.add_argument('--tournament', type=int, default=3,
                       help='–†–∞–∑–º–µ—Ä —Ç—É—Ä–Ω–∏—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)')
    cmd_ga.add_argument('--learning-curves', action='store_true',
                       help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è')
    cmd_ga.add_argument('--auto-save', '--save-best', action='store_true',
                       help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å')
    
    # –ö–æ–º–∞–Ω–¥–∞ predict
    cmd_predict = subparsers.add_parser(
        'predict',
        help='–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º'
    )
    cmd_predict.add_argument('--model', required=True,
                           help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –∏–ª–∏ –∏–º—è –º–æ–¥–µ–ª–∏')
    cmd_predict.add_argument('--data', required=True,
                           help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
    cmd_predict.add_argument('--output',
                           help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    # –ö–æ–º–∞–Ω–¥–∞ list-models
    cmd_list = subparsers.add_parser(
        'list-models',
        help='–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π'
    )
    cmd_list.add_argument('--verbose', action='store_true',
                         help='–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    cli = MLPipelineCLI()
    
    # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥
    if args.command == 'run-chromosome':
        success = cli.run_chromosome(args)
    elif args.command == 'run-ga':
        success = cli.run_ga(args)
    elif args.command == 'predict':
        success = cli.predict(args)
    elif args.command == 'list-models':
        success = cli.list_models(args)
    else:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {args.command}")
        return 1
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main()) 